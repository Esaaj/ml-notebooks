{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "614b08ef",
   "metadata": {},
   "source": [
    "### ***naive bayes algorithm*** ### \n",
    "It is based on bayes theorem which describes the probability of an event based on prior knowledge of conditions that might be related to the event.\n",
    "\n",
    "```math\n",
    "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "```\n",
    "\n",
    "where,\n",
    "\n",
    "P(A|B) is the posterior probability of class A given predictor B.\n",
    "\n",
    "P(B|A) is the likelihood which is the probability of predictor B given class A.\n",
    "\n",
    "P(A) is the prior probability of class A.\n",
    "\n",
    "P(B) is the prior probability of predictor B.\n",
    "\n",
    "naive bayes is particularly suited for high-dimensional data and is often used in text classification, spam detection, and sentiment analysis.\n",
    "    \n",
    "types of naive bayes:\n",
    "1. Gaussian Naive Bayes: assumes that the features follow a normal distribution.\n",
    "2. Multinomial Naive Bayes: used for discrete data, particularly in text classification where features represent word counts or frequencies.\n",
    "3. Bernoulli Naive Bayes: used for binary/boolean\n",
    "features, where each feature is either present or absent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed91e1b4",
   "metadata": {},
   "source": [
    "***Laplace smoothing***\n",
    "\n",
    "In practice, we multiply probabilities instead of adding them, but if one feature has a probability of zero, the entire product becomes zero. Laplace smoothing prevents this by ensuring no probability is ever exactly zero.\n",
    "\n",
    "laplace smoothing is used to handle zero probabilities by adding a small constant (usually 1) to each count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02441ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of naive bayes in python using sklearn\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "\n",
    "# where GaussianNB is used for continuous data\n",
    "# MultinomialNB is used for discrete data\n",
    "# BernoulliNB is used for binary data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e49f00",
   "metadata": {},
   "source": [
    "***Order of implementation***\n",
    "\n",
    "1. Import necessary libraries\n",
    "2. Load the dataset\n",
    "3. Data preprocessing\n",
    "4. Split dataset into training and testing sets\n",
    "5. Choose the Naive Bayes model type (Gaussian / Multinomial / Bernoulli)\n",
    "6. Train the model\n",
    "7. Make predictions\n",
    "8. Evaluate the model (accuracy, confusion matrix, report)\n",
    "9. Apply Laplace smoothing (optional, for manual probability calculation)\n",
    "10. Visualize results (optional)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
