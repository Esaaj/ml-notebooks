{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b425c871",
   "metadata": {},
   "source": [
    "### ***Collaborative filtering***\n",
    "\n",
    "Collaborative filtering is a method used by recommender systems to make automatic predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating). \n",
    "\n",
    "The underlying assumption of the collaborative filtering approach is that if a person A has the same opinion as a person B on an issue, A is more likely to have B's opinion on a different issue than that of a randomly chosen person.\n",
    "\n",
    "- User-user collaborative filtering - Use user similarity matrix to recommend items liked by similar users\n",
    "- Hybrid methods - Combine collaborative filtering and content-based filtering for better recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bb2bd3",
   "metadata": {},
   "source": [
    "***Types of Collaborative Filtering***\n",
    "- User-user collaborative filtering - Use user similarity matrix to recommend items liked by similar users\n",
    "- Item-item collaborative filtering - Use item similarity matrix to recommend similar items\n",
    "- Hybrid methods - Combine collaborative filtering and content-based filtering for better recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4e7299",
   "metadata": {},
   "source": [
    "***User-Based CF***\n",
    "\n",
    "- Finds users similar to the target user\n",
    "- Recommends items liked by similar users\n",
    "\n",
    "üìò Example:\n",
    "- ‚ÄúPeople who have similar movie tastes to you also liked Interstellar.‚Äù\n",
    "\n",
    "üîß Uses: Cosine similarity or Pearson correlation between user rating vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605b5959",
   "metadata": {},
   "source": [
    "***Item-Based CF***\n",
    "- Finds items similar to the ones the user liked\n",
    "- Recommends similar items\n",
    "\n",
    "üìò Example:\n",
    "    - ‚ÄúSince you liked Inception, you might like Shutter Island.‚Äù\n",
    "\n",
    "üîß Uses: Similarity between item rating vectors (columns instead of rows)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2042c8",
   "metadata": {},
   "source": [
    "***Order of implementation***\n",
    "\n",
    "1. Import necessary libraries  \n",
    "    - pandas, numpy, scipy.sparse, sklearn.metrics, sklearn.model_selection  \n",
    "    - similarity / nearest-neighbors: sklearn.neighbors, sklearn.metrics.pairwise or libraries like implicit, faiss  \n",
    "    - optional: surprise, lightfm, matplotlib / seaborn for EDA and plotting\n",
    "\n",
    "2. Load the dataset  \n",
    "    - read CSV/Parquet or database, inspect columns (user_id, item_id, rating, timestamp)  \n",
    "    - handle duplicates, outliers, and type conversions  \n",
    "    - create time-based train/validation/test splits if applicable\n",
    "\n",
    "3. Create a user‚Äìitem matrix  \n",
    "    - pivot to dense or sparse matrix (scipy.sparse.csr_matrix)  \n",
    "    - preserve implicit feedback (counts) vs explicit ratings semantics  \n",
    "    - keep mappings for user_id/item_id ‚Üî matrix indices\n",
    "\n",
    "4. Handle missing values and normalization  \n",
    "    - for explicit CF: leave as NaN and predict only missing entries, or mean-center rows for similarity  \n",
    "    - for implicit CF: convert to binary or confidence-weighted values (e.g., confidence = 1 + alpha * interactions)  \n",
    "    - apply global/user/item bias removal or scaling as needed\n",
    "\n",
    "5. Compute similarity matrix  \n",
    "    - user-based: cosine, Pearson correlation, or adjusted cosine (mean-centering)  \n",
    "    - item-based: cosine or item-item correlation (columns)  \n",
    "    - optimize: compute only top-k neighbors, use approximate nearest neighbors or sparse operations\n",
    "\n",
    "6. Predict missing ratings (scoring)  \n",
    "    - neighborhood-based: weighted sum of neighbor ratings with normalization and regularization  \n",
    "    - model-based: matrix factorization (ALS, SGD), factorization machines, or neural approaches  \n",
    "    - apply baseline corrections (global/user/item biases) to reduce systematic error\n",
    "\n",
    "7. Generate top‚ÄëN recommendations  \n",
    "    - score candidate items, exclude already-observed items for the user  \n",
    "    - rerank by diversity / serendipity / popularity penalties if required  \n",
    "    - return item ids with scores and explanations (optional)\n",
    "\n",
    "8. Evaluate model performance  \n",
    "    - rating prediction: RMSE, MAE  \n",
    "    - ranking: Precision@K, Recall@K, MAP@K, NDCG@K, Hit Rate  \n",
    "    - use stratified or temporal cross-validation and holdout sets; evaluate offline-to-online gap\n",
    "\n",
    "9. (Optional) Apply dimensionality reduction / latent-factor models  \n",
    "    - SVD / truncated SVD, ALS, NMF; choose number of latent factors and regularization  \n",
    "    - compare latent models vs neighborhood methods on your metrics\n",
    "\n",
    "10. (Optional) Tune hyperparameters and selection criteria  \n",
    "     - grid or random search for similarity metric, neighborhood size k, regularization, learning rate, latent factors  \n",
    "     - use validation metrics and early stopping; consider computational cost\n",
    "\n",
    "11. Production and deployment considerations  \n",
    "     - handle cold-start (side information / hybrid methods), incremental updates, and batch retraining cadence  \n",
    "     - scale with sharding, approximate nearest neighbors, or precomputed candidate lists  \n",
    "     - monitor drift, A/B test online, and ensure privacy/compliance (anonymization, consent)\n",
    "\n",
    "12. Documentation and reproducibility  \n",
    "     - log data provenance, preprocessing steps, hyperparameters, and model artifacts  \n",
    "     - provide reproducible notebooks, unit tests for core transformation functions, and CI for retraining pipelines"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
